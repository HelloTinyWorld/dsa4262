{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 11027106 feature rows from task1/dataset0.json.gz\n",
      "Parsed DataFrame shape: (11027106, 12)\n",
      "Info DataFrame shape (after cleaning): (121838, 4)\n",
      "Merged DataFrame shape: (11027106, 14)\n",
      "Rows with matching gene_id/label from info file: 11027106 / 11027106\n",
      "Saved merged dataframe to: task1/parsed_dataset0.csv\n",
      "\n",
      "First 5 rows of merged dataframe:\n",
      "  transcript_id  position    kmer   feat1  feat2  feat3   feat4  feat5  feat6   feat7  feat8  feat9         gene_id  label\n",
      "ENST00000000233       244 AAGACCA 0.00299   2.06  125.0 0.01770  10.40  122.0 0.00930  10.90   84.1 ENSG00000004059      0\n",
      "ENST00000000233       244 AAGACCA 0.00631   2.53  125.0 0.00844   4.67  126.0 0.01030   6.30   80.9 ENSG00000004059      0\n",
      "ENST00000000233       244 AAGACCA 0.00465   3.92  109.0 0.01360  12.00  124.0 0.00498   2.13   79.6 ENSG00000004059      0\n",
      "ENST00000000233       244 AAGACCA 0.00398   2.06  125.0 0.00830   5.01  130.0 0.00498   3.78   80.4 ENSG00000004059      0\n",
      "ENST00000000233       244 AAGACCA 0.00664   2.92  120.0 0.00266   3.94  129.0 0.01300   7.15   82.2 ENSG00000004059      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------\n",
    "TASK1_DIR = \"task1\"\n",
    "JSON_FILE = os.path.join(TASK1_DIR, \"dataset0.json.gz\")\n",
    "INFO_LABEL_FILE = os.path.join(TASK1_DIR, \"data.info.labelled\")\n",
    "PARSED_CSV_OUTPUT = os.path.join(TASK1_DIR, \"parsed_dataset0.csv\")\n",
    "\n",
    "# Ensure task1 exists and files are present\n",
    "if not os.path.isdir(TASK1_DIR):\n",
    "    raise FileNotFoundError(f\"Directory '{TASK1_DIR}' not found.\")\n",
    "if not os.path.exists(JSON_FILE):\n",
    "    raise FileNotFoundError(f\"JSON file not found: {JSON_FILE}\")\n",
    "if not os.path.exists(INFO_LABEL_FILE):\n",
    "    raise FileNotFoundError(f\"Info/label file not found: {INFO_LABEL_FILE}\")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 1: PARSE dataset0.json.gz INTO ROWS\n",
    "# --------------------------\n",
    "rows = []\n",
    "parsed_count = 0\n",
    "with gzip.open(JSON_FILE, \"rt\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        # Each line is a JSON object mapping transcript_id -> positions\n",
    "        for transcript_id, positions in obj.items():\n",
    "            for position, kmers in positions.items():\n",
    "                # position in JSON may be string or number; keep as int\n",
    "                try:\n",
    "                    pos_int = int(position)\n",
    "                except Exception:\n",
    "                    # skip malformed position\n",
    "                    continue\n",
    "                for kmer, feature_lists in kmers.items():\n",
    "                    for feats in feature_lists:\n",
    "                        # each feats should be list of length 9\n",
    "                        if isinstance(feats, (list, tuple)) and len(feats) == 9:\n",
    "                            rows.append({\n",
    "                                \"transcript_id\": transcript_id,\n",
    "                                \"position\": pos_int,\n",
    "                                \"kmer\": kmer,\n",
    "                                \"feat1\": feats[0],\n",
    "                                \"feat2\": feats[1],\n",
    "                                \"feat3\": feats[2],\n",
    "                                \"feat4\": feats[3],\n",
    "                                \"feat5\": feats[4],\n",
    "                                \"feat6\": feats[5],\n",
    "                                \"feat7\": feats[6],\n",
    "                                \"feat8\": feats[7],\n",
    "                                \"feat9\": feats[8]\n",
    "                            })\n",
    "                            parsed_count += 1\n",
    "\n",
    "print(f\"Parsed {parsed_count} feature rows from {JSON_FILE}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Parsed DataFrame shape:\", df.shape)\n",
    "if df.shape[0] == 0:\n",
    "    raise ValueError(\"No rows parsed from JSON. Check the JSON file and parsing logic.\")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 2: READ data.info.labelled (CSV with header)\n",
    "# Expect header: gene_id,transcript_id,transcript_position,label\n",
    "# --------------------------\n",
    "# Read with pandas; it will automatically parse the header if present.\n",
    "info_df = pd.read_csv(INFO_LABEL_FILE)\n",
    "\n",
    "# Validate expected columns exist\n",
    "expected_cols = {\"gene_id\", \"transcript_id\", \"transcript_position\", \"label\"}\n",
    "if not expected_cols.issubset(set(info_df.columns)):\n",
    "    raise ValueError(\n",
    "        f\"Info file columns mismatch. Expected at least {expected_cols}; found {set(info_df.columns)}\"\n",
    "    )\n",
    "\n",
    "# Rename the position column to 'position' to match parsed df\n",
    "info_df = info_df.rename(columns={\"transcript_position\": \"position\"})\n",
    "\n",
    "# Coerce position to numeric, drop invalid rows\n",
    "info_df[\"position\"] = pd.to_numeric(info_df[\"position\"], errors=\"coerce\")\n",
    "before_drop = len(info_df)\n",
    "info_df = info_df.dropna(subset=[\"position\"])\n",
    "dropped = before_drop - len(info_df)\n",
    "if dropped:\n",
    "    print(f\"Warning: Dropped {dropped} rows from info file due to invalid 'position' values.\")\n",
    "# convert to int now (safe)\n",
    "info_df[\"position\"] = info_df[\"position\"].astype(int)\n",
    "\n",
    "# Ensure label is integer if possible\n",
    "if info_df[\"label\"].dtype != int:\n",
    "    info_df[\"label\"] = pd.to_numeric(info_df[\"label\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "print(\"Info DataFrame shape (after cleaning):\", info_df.shape)\n",
    "\n",
    "# --------------------------\n",
    "# STEP 3: MERGE parsed JSON data with info_df\n",
    "# --------------------------\n",
    "# Merge on transcript_id and position\n",
    "merged = df.merge(\n",
    "    info_df[[\"gene_id\", \"transcript_id\", \"position\", \"label\"]],\n",
    "    on=[\"transcript_id\", \"position\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"  # many parsed rows can map to single info row\n",
    ")\n",
    "\n",
    "print(\"Merged DataFrame shape:\", merged.shape)\n",
    "\n",
    "# Report merge stats\n",
    "num_with_info = merged[\"gene_id\"].notna().sum()\n",
    "print(f\"Rows with matching gene_id/label from info file: {num_with_info} / {len(merged)}\")\n",
    "\n",
    "# --------------------------\n",
    "# STEP 4: SAVE RESULT\n",
    "# --------------------------\n",
    "merged.to_csv(PARSED_CSV_OUTPUT, index=False)\n",
    "print(f\"Saved merged dataframe to: {PARSED_CSV_OUTPUT}\")\n",
    "\n",
    "# Optional: display first few rows\n",
    "print(\"\\nFirst 5 rows of merged dataframe:\")\n",
    "print(merged.head().to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique gene_ids: 3852\n"
     ]
    }
   ],
   "source": [
    "df = merged\n",
    "# Number of unique gene_ids\n",
    "num_genes = df['gene_id'].nunique()\n",
    "print(\"Number of unique gene_ids:\", num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8786719\n",
      "Test size: 2240387\n",
      "Train label distribution:\n",
      " label\n",
      "0    0.953795\n",
      "1    0.046205\n",
      "Name: proportion, dtype: float64\n",
      "Test label distribution:\n",
      " label\n",
      "0    0.958227\n",
      "1    0.041773\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume df has 'gene_id' and 'label' columns\n",
    "\n",
    "# First, get unique gene_ids with their label (majority label for that gene)\n",
    "gene_labels = df.groupby('gene_id')['label'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "# Split gene_ids into train/test while stratifying by label\n",
    "train_genes, test_genes = train_test_split(\n",
    "    gene_labels['gene_id'],\n",
    "    test_size=0.2,                # 20% genes for test\n",
    "    stratify=gene_labels['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Select rows corresponding to train/test genes\n",
    "train_df = df[df['gene_id'].isin(train_genes)].reset_index(drop=True)\n",
    "test_df = df[df['gene_id'].isin(test_genes)].reset_index(drop=True)\n",
    "\n",
    "# Check sizes\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "# Optional: check label balance\n",
    "print(\"Train label distribution:\\n\", train_df['label'].value_counts(normalize=True))\n",
    "print(\"Test label distribution:\\n\", test_df['label'].value_counts(normalize=True))\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(\"task1/train_set.csv\", index=False)\n",
    "test_df.to_csv(\"task1/test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check passed ✅: No gene_ids in test are in train.\n"
     ]
    }
   ],
   "source": [
    "# Find overlapping gene_ids\n",
    "overlap_genes = set(train_df['gene_id']).intersection(set(test_df['gene_id']))\n",
    "\n",
    "if len(overlap_genes) == 0:\n",
    "    print(\"Check passed ✅: No gene_ids in test are in train.\")\n",
    "else:\n",
    "    print(\"Check failed ❌: Overlapping gene_ids found:\", overlap_genes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa4262",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
